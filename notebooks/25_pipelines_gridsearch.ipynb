{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Completing the ML workflow\n",
    "\n",
    "Over the past few tutorials we've seen many aspects of a supervised ML workflow. From loading data to preprocessing, selecting and training a model, optimizing hyperparameters and finally evaluating the model. It's time to put all these together into a complete workflow for supervised ML problems.\n",
    "\n",
    "<img src=\"https://github.com/rasbt/pattern_classification/raw/master/Images/supervised_learning_flowchart.png\" width=\"65%\">\n",
    "\n",
    "The main steps are:\n",
    "\n",
    "1. **Load** the data into python\n",
    "2. **Split** the data into train/test sets\n",
    "3. **Preprocess** the data\n",
    "\n",
    "    1. Perform all **necessary** preprocessing steps. These include:\n",
    "        - Handling **missing** data (i.e. discard or impute)\n",
    "        - Feature **encoding** (i.e. convert alphanumeric features into numeric)\n",
    "        - Feature **scaling** (i.e. transform features so that they occupy similar value ranges) \n",
    "        \n",
    "    2. **Optionally** we might want to perform:\n",
    "        - Feature **selection** (i.e. discard some of the features)\n",
    "        - Feature **extraction** (i.e. transform the data into a usually smaller feature space)\n",
    "        - **Resampling** (i.e. under/over-sampling)\n",
    "4. **Select** a ML algorithm\n",
    "5. Optimize the algorithm's **hyperparameters** through **cross-validation**.\n",
    "6. **Evaluate** its performance on the test set. If it is inadequate, or if we want to improve on the results: **start over from step 2 and refine the process**! \n",
    "7. Finally, if we've achieved an adequate performance on the test set: train the model one last time, with the optimal hyperparameters, **on the whole dataset**.\n",
    "\n",
    "Scikit-learn has two very helpful classes that make our life easier when refining hyperparameters: **pipeline** and **grid search**.\n",
    "\n",
    "## pipeline\n",
    "\n",
    "*scikit-learn* [pipelines](http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) provide a convenient way for incorporating multiple steps in a ML workflow.\n",
    "\n",
    "The concept of the `pipeline` is to encapsulate more than one steps into a single class. The first steps of the pipeline involve **preprocessing** steps. Through these the data is transformed accordingly. The last step of the pipeline is a model that can make predictions. Unfortunately **all preprocessing steps must be *scikit-learn* compatible objects**.\n",
    "\n",
    "All intermediate steps in a pipeline are transforms and must implement both a `.fit()` and a `.transform()` argument (like the scaler we saw before). The last step should be an estimator (i.e. have `.fit()` and `.predict()` methods). We need to pass these steps, sequentially, as a *list* of *tuples*, each containing the name and object of the transform/estimator.\n",
    "\n",
    "```python\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe = Pipeline([('transform1', transform1), ('transform2', transform2), ..., ('estimator', estimator)])\n",
    "```\n",
    "\n",
    "Let's try to implement a pipeline containing a StandardScaler and a k-NN model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.956140350877193\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import datasets\n",
    "\n",
    "# Load the iris dataset\n",
    "iris = datasets.load_breast_cancer()\n",
    "\n",
    "seed = 13  # random seed for reproducibility\n",
    "\n",
    "# Shuffle and split the data\n",
    "train, test, train_labels, test_labels = train_test_split(iris['data'], iris['target'], test_size=0.4, random_state=seed)\n",
    "\n",
    "# Define a scaler (default parameters)\n",
    "scaler = StandardScaler() \n",
    "\n",
    "# Define a kNN model (not default parameters)\n",
    "knn = KNeighborsClassifier(n_neighbors=11)\n",
    "\n",
    "# Create a pipeline with the scaler and the kNN\n",
    "pipe = Pipeline([('standardizer', scaler), ('classifier', knn)])\n",
    "\n",
    "# Train on the training set\n",
    "pipe.fit(train, train_labels)\n",
    "\n",
    "# Evaluate on the test set\n",
    "preds = pipe.predict(test)\n",
    "print(accuracy_score(test_labels, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What the pipeline did is that when we called `pipe.fit()`, internally it called `.fit_transform()` **for each of its transforms** and `.fit()` **for its estimator**. Assuming an estimator with $M$ preprocessing steps, when we called `pipe.fit()` it ran the equivalent of fitting and transforming the data through each of the preprocessing steps and fitting the last step (i.e. the estimator)\n",
    "\n",
    "```python\n",
    "# Assuming that our pipeline is:\n",
    "pipe = Pipeline([('transform1', transform1), ('transform2', transform2), ..., ('estimator', estimator)])\n",
    "\n",
    "# If we ran:\n",
    "pipe.fit(train, train_labels)\n",
    "\n",
    "# It would be the equivalent of:\n",
    "tmp = transform1.fit_transform(train)\n",
    "tmp = transform2.fit_transform(tmp)\n",
    "# ...\n",
    "tmp = transformM.fit_transform(tmp)\n",
    "estimator.fit(tmp)\n",
    "```\n",
    "\n",
    "Running `pipe.predict()`, on the other hand, simply applied `.transform()` to each of the preprocessing steps and `.predict()` to the final step.\n",
    "\n",
    "```python\n",
    "# If we ran:\n",
    "preds = pipe.predict(test, test_labels)\n",
    "\n",
    "# It would be the equivalent of:\n",
    "tmp = transform1.transform(test)\n",
    "tmp = transform2.transform(tmp)\n",
    "# ...\n",
    "tmp = transformM.transform(tmp)\n",
    "preds = estimator.predict(tmp)\n",
    "```\n",
    "\n",
    "An easier way to create Pipelines is through scikit-learn `make_pipeline` function. This is a shorthand for the Pipeline constructor, that does not require naming the estimators. Instead, their names will be set to the lowercase of their types automatically.\n",
    "\n",
    "```python\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pipe = make_pipeline(scaler, knn) \n",
    "```\n",
    "\n",
    "**Note**: If we want to put a sampler from imblearn into our pipeline we **must** use ` imblearn.pipeline.Pipeline` which extends sklearn's pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline  # import imblearn's pipeline because one of the steps is SMOTE\n",
    "\n",
    "\n",
    "pipe = Pipeline([('selector', VarianceThreshold()),\n",
    "                 ('scaler', StandardScaler()),\n",
    "                 ('sampler', SMOTE()),\n",
    "                 ('pca', PCA()),\n",
    "                 ('knn', KNeighborsClassifier())])\n",
    "\n",
    "pipe.fit(train, train_labels)\n",
    "\n",
    "preds = pipe.predict(test)\n",
    "print(accuracy_score(test_labels, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search\n",
    "\n",
    "Before, we attempted to optimize a model by selecting its hyperparameters through a for loop. There is a much easier way provided through scikit-learn's [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV). This function takes two main arguments: an estimator (or pipeline) and a *grid* of parameters we want the grid search to consider. The grid could be one of two things:\n",
    "\n",
    "- A dictionary with the hyperparameter names as its keys and a list of values as the corresponding dictionary value:\n",
    "```python\n",
    "grid = {'name1': [val1, val2, val3], 'name2': [val4, val5], ...}\n",
    "```\n",
    "This will force the grid search to search for **all** possible combinations of parameter values:  \n",
    "```python\n",
    "(val1, val4, ...), (val1, val5, ...), (val2, val4, ...), (val2, val5, ...), ... etc.\n",
    "```\n",
    "\n",
    "- A list of such dictionaries:\n",
    "```python\n",
    "grid = [{'name1': [val1, val2, val3], 'name2': [val4, val5], ...},\n",
    "        {'name1': [val1, val2, val3], 'name3': [val6, val7], ...}]\n",
    "```\n",
    "This will create a grid that contains combinations from both dictionaries.\n",
    "\n",
    "After creating such a grid:\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid = {...}\n",
    "clf = GridSearchCV(estimator, grid)\n",
    "clf.fit(X_train, y_train)  # will search all possible combinations defined by the grid\n",
    "preds = clf.predict(X_test)  # will generate predictions based on the best configuration\n",
    "\n",
    "# In order to access the best model:\n",
    "clf.best_estimator_\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9780701754385965\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=None, n_neighbors=3, p=1,\n",
      "           weights='uniform')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Scale the data to be comparable to previous.\n",
    "scaled_train = scaler.fit_transform(train)\n",
    "scaled_test = scaler.transform(test)\n",
    "\n",
    "# Define a search grid.\n",
    "grid = {'n_neighbors': list(range(1, 15, 2)), \n",
    "        'p': [1, 2, 3, 4]}\n",
    "\n",
    "# Create the GridSearch class. This will serve as our classifier from now on.\n",
    "clf = GridSearchCV(knn, grid, cv=5)  # 5-fold cross validation\n",
    "\n",
    "# Train the model as many times as designated by the grid.\n",
    "clf.fit(scaled_train, train_labels)\n",
    "\n",
    "# Evaluate on the test set and print best hyperparameters\n",
    "preds = clf.predict(scaled_test)\n",
    "print(accuracy_score(test_labels, preds))\n",
    "print(clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid searches can be performed on pipelines too! The only thing that changes is that now we need to specify which step each parameter belongs to. This is done by adding both the name of the step and the name of the parameter separated by two underscores (i.e. `__`). \n",
    "\n",
    "```python\n",
    "pipe = Pipeline([('step1', ...), ...])\n",
    "grid = {'step1__param1`': [val1, ...], ...}  # this dictates param1 from step1 to take the values [val1, ...]\n",
    "clf = GridSearchCV(pipe, grid)\n",
    "clf.fit(X_train, y_train)  # will search all possible combinations defined by the grid\n",
    "preds = clf.predict(X_test)  # will generate predictions based on the best configuration\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 97.37%\n",
      "Pipeline(memory=None,\n",
      "     steps=[('standardizer', StandardScaler(copy=True, with_mean=True, with_std=True)), ('classifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=None, n_neighbors=5, p=1,\n",
      "           weights='uniform'))])\n"
     ]
    }
   ],
   "source": [
    "# Revert to the previous pipeline\n",
    "pipe = Pipeline([('standardizer', scaler), ('classifier', knn)])\n",
    "\n",
    "# Define a grid that checks for hyperparameters for both steps\n",
    "grid = {'standardizer__with_mean': [True, False],  # Check parameters True/False for 'with_mean' argument of scaler\n",
    "        'standardizer__with_std': [True, False],  # Check parameters True/False for 'with_std' argument of scaler\n",
    "        'classifier__n_neighbors': list(range(1, 15, 2)),  # Check for values of 'n_neighbors' of knn\n",
    "        'classifier__p': [1, 2, 3, 4]}  # Check for values of 'p' of knn\n",
    "\n",
    "# Create and train the grid search\n",
    "clf = GridSearchCV(pipe, grid, cv=5)\n",
    "clf.fit(train, train_labels)\n",
    "\n",
    "# Evaluate on the test set and print best hypterparameter values\n",
    "print('Best accuracy: {:.2f}%'.format(accuracy_score(test_labels, clf.predict(test))*100))\n",
    "print(clf.best_estimator_)  # print the best configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to optimize the more complex pipeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 96.49%\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selector', VarianceThreshold(threshold=0.0)), ('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('sampler', SMOTE(k_neighbors=5, kind='deprecated', m_neighbors='deprecated', n_jobs=1,\n",
      "   out_step='deprecated', random_state=None, ratio=None,\n",
      "   sampling_strategy='auto', s...ki',\n",
      "           metric_params=None, n_jobs=None, n_neighbors=5, p=1,\n",
      "           weights='uniform'))])\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline(steps=[('selector', VarianceThreshold()),\n",
    "                       ('scaler', StandardScaler()),\n",
    "                       ('sampler', SMOTE()),\n",
    "                       ('pca', PCA()),\n",
    "                       ('knn', KNeighborsClassifier())])\n",
    "\n",
    "grid = {'selector__threshold': [0.0, 0.005],\n",
    "        'pca__n_components': list(range(5, 16, 5)),\n",
    "        'knn__n_neighbors': list(range(1, 15, 2)),\n",
    "        'knn__p': [1, 2, 3, 4]}\n",
    "\n",
    "clf = GridSearchCV(pipe, grid, cv=5)\n",
    "clf.fit(train, train_labels)\n",
    "\n",
    "print('Best accuracy: {:.2f}%'.format(accuracy_score(test_labels, clf.predict(test)) * 100))\n",
    "print(clf.best_estimator_) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the inclusion of the feature selection/extraction steps, we actually managed to **hurt** our performance here.\n",
    "\n",
    "### Tips for using grid search:\n",
    "\n",
    "1. Always **calculate** the number of times a model is fit. In the example above we check for $2 \\cdot 3 \\cdot 4 \\cdot 4 = 168$ different hyperparameter combinations. Because we are using a 5-fold cross validation, each combination is used for 5 separate model fits. So the above grid search accounts for 840 different fits! It is very easy when using a grid search for this number to go up to the thousands which would take a **long time to complete**. If we were using a feature selection or imputing through a model, we would need to take that into account too!\n",
    "\n",
    "2. Grid search has a parameter called `verbose` which offers several **levels of verbosity**. I'd recommend setting a `verbose=1` so that *scikit-learn* informs you on the number of times a model needs to be trained and how much time it took. You can, however, set a larger value which will inform you on the progress of each fit in detail. Caution: this will flood your screen!\n",
    "\n",
    "3. Instead of checking all different parameter combinations which would be computationally impossible to achieve, we could use a more **progressive** grid search! Imagine we want to optimize a hyperparameter `x` that ranges from $1$ to $1000$:\n",
    " - First perform a grid search on `[1, 5, 10, 50, 100, 500, 1000]` (or even more sparse if it takes too long). We get the best performance for $x = 500$.\n",
    " - Now perform a grid search on `[200, 350, 500, 650, 800]`. The best performance is produced with $x=800$.\n",
    " - Choose an even more close grid `[725, 730, 735, 740, 745, 750]`.\n",
    " - Repeat until you achieve the desired precision.\n",
    "\n",
    "4. `GridSearchCV` has a parameter called `n_jobs`. This can determine the number of jobs to run in parallel. This can increase computation time, but might criple your pc.\n",
    "\n",
    "\n",
    "### Drawbacks:\n",
    "\n",
    "One major drawback of using pipelines is that they support only scikit-learn compatible objects. Many preprocessing steps, however, need to be implemented in a library like *pandas*. To refine these steps we'll need to do so manually! Either that or you can write your own class in an sklearn-like manner and incorporate them into a pipeline. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
